import streamlit as st
import cv2
import numpy as np
import tempfile
from PIL import Image
import os
import io
from pathlib import Path

# Import t·ª´ c√°c file module ƒë√£ chia
from haar_detector import load_haar, detect_faces_haar
from dnn_detector import load_dnn, detect_faces_dnn
from apply_blur import apply_blur_to_image

st.set_page_config(page_title="Face Blurring (Privacy Filter)", layout="centered")

# ---------------- UI ----------------

st.title("üîí Face Blurring ‚Äî Privacy Filter")
st.write("Upload an image or video. Detect faces (Haar / DNN) and Blur (Gaussian or Pixelate).")

with st.sidebar:
    st.header("Settings")

    detector = st.selectbox("Face detector", ("Haar Cascade (fast)", "DNN (more accurate)"))
    blur_method = st.selectbox("Blur method", ("Gaussian", "Pixelate"))
    draw_boxes = st.checkbox("Draw detection boxes (for debug)", value=False)

    gaussian_kernel = (51, 51)
    pixel_blocks = 10

    if blur_method == "Gaussian":
        k = st.slider("Gaussian kernel size (odd)", 11, 101, 51, step=2)
        gaussian_kernel = (k, k)
    else:
        pixel

    st.markdown("---")
    st.write("DNN model (optional):")
    prototxt_path = st.text_input("Prototxt path (deploy.prototxt)", "")
    model_path = st.text_input("Caffe model path (res10_300x300.caffemodel)", "")
    st.info("N·∫øu ch·ªçn DNN th√¨ nh·∫≠p ƒë·ªß 2 file model.")

tab1, tab2, tab3 = st.tabs(["Upload File", "Ch·ª•p t·ª´ Webcam", "Webcam Live Blur (Realtime)"])

# Bi·∫øn uploaded v·∫´n gi·ªØ nguy√™n ƒë·ªÉ code c≈© ch·∫°y ngon
uploaded = None

# ==================== TAB 1: UPLOAD FILE  ====================
with tab1:
    uploaded = st.file_uploader(
        "Choose an image or video",
        type=["jpg","jpeg","png","bmp","mp4","mov","avi","mkv"],
        accept_multiple_files=False
    )

# ==================== TAB 2: CH·ª§P ·∫¢NH T·ª™ WEBCAM  ====================
with tab2:
    st.write("### 2) Ch·ª•p ·∫£nh t·ª´ Webcam")
    camera_img = st.camera_input("Nh·∫•n ƒë·ªÉ ch·ª•p", key="static_cam")
    if camera_img:
        uploaded = camera_img  # g√°n v√†o uploaded ‚Üí code x·ª≠ l√Ω c≈© v·∫´n ch·∫°y b√¨nh th∆∞·ªùng
        st.success("ƒê√£ ch·ª•p t·ª´ webcam!")

# ==================== TAB 3: WEBCAM REALTIME BLUR ====================
with tab3:
    st.write("### Webcam Live ‚Äì L√†m m·ªù khu√¥n m·∫∑t realtime")
    st.info("Camera s·∫Ω b·∫≠t ngay ‚Äì khu√¥n m·∫∑t s·∫Ω b·ªã l√†m m·ªù tr·ª±c ti·∫øp!")

    # Kh·ªüi t·∫°o model m·ªôt l·∫ßn duy nh·∫•t
    if "face_detector" not in st.session_state:
        if detector == "DNN (more accurate)" and prototxt_path and model_path:
            try:
                st.session_state.face_detector = load_dnn(prototxt_path, model_path)
                st.session_state.detector_type = "dnn"
                st.success("ƒê√£ t·∫£i DNN model th√†nh c√¥ng!")
            except:
                st.error("L·ªói t·∫£i DNN model ‚Üí chuy·ªÉn v·ªÅ Haar Cascade")
                st.session_state.face_detector = load_haar()
                st.session_state.detector_type = "haar"
        else:
            st.session_state.face_detector = load_haar()
            st.session_state.detector_type = "haar"

    # Frame placeholder ƒë·ªÉ hi·ªÉn th·ªã realtime
    frame_placeholder = st.empty()

    # N√∫t b·∫≠t/t·∫Øt webcam realtime
    if st.button("B·∫≠t Webcam Realtime", type="primary", use_container_width=True):
        st.session_state.run_webcam = True
    if st.button("T·∫Øt Webcam", use_container_width=True):
        st.session_state.run_webcam = False

    # Ch·∫°y webcam realtime
    if st.session_state.get("run_webcam", False):
        cap = cv2.VideoCapture(0)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

        while st.session_state.run_webcam:
            ret, frame = cap.read()
            if not ret:
                st.error("Kh√¥ng th·ªÉ truy c·∫≠p webcam!")
                break

            # Ph√°t hi·ªán khu√¥n m·∫∑t
            if st.session_state.detector_type == "dnn":
                boxes = detect_faces_dnn(frame, st.session_state.face_detector, conf_threshold=0.5)
            else:
                boxes = detect_faces_haar(frame, st.session_state.face_detector)

            # L√†m m·ªù khu√¥n m·∫∑t
            blurred_frame = apply_blur_to_image(
                frame,
                boxes,
                method="gaussian" if blur_method == "Gaussian" else "pixelate",
                gaussian_kernel=gaussian_kernel,
                pixel_blocks=pixel_blocks,
                draw_boxes=draw_boxes
            )

            # Chuy·ªÉn BGR ‚Üí RGB ƒë·ªÉ hi·ªÉn th·ªã ƒë√∫ng m√†u
            blurred_frame_rgb = cv2.cvtColor(blurred_frame, cv2.COLOR_BGR2RGB)

            # Hi·ªÉn th·ªã frame realtime
            frame_placeholder.image(blurred_frame_rgb, channels="RGB", use_column_width=True)

        cap.release()
        frame_placeholder.empty()  # x√≥a khung h√¨nh khi t·∫Øt

# ---------------- Session state ----------------
for key in ["original_img", "processed_img", "original_video_file", "processed_video_file"]:
    if key not in st.session_state:
        st.session_state[key] = None

# N·∫øu b·∫°n c√≥ th√™m d√≤ng ki·ªÉm tra uploaded ·ªü d∆∞·ªõi (v√≠ d·ª• x·ª≠ l√Ω ·∫£nh/video), 
# th√¨ gi·ªù n√≥ s·∫Ω nh·∫≠n c·∫£ ·∫£nh t·ª´ webcam m√† KH√îNG C·∫¶N S·ª¨A G√å H·∫æT

# ---------------- Load models ----------------

face_cascade = load_haar()
dnn_net = None

if detector.startswith("DNN") and prototxt_path and model_path:
    try:
        dnn_net = load_dnn(prototxt_path, model_path)
    except Exception as e:
        st.error(f"Failed to load DNN: {e}")
        dnn_net = None

#-------
def process_image_file(file_bytes):

    file_bytes.seek(0)
    file_bytes_bytes = np.asarray(bytearray(file_bytes.read()), dtype=np.uint8)
    img = cv2.imdecode(file_bytes_bytes, cv2.IMREAD_COLOR)
    if img is None:
        st.error("Kh√¥ng th·ªÉ ƒë·ªçc file ·∫£nh. H√£y th·ª≠ ƒë·ªãnh d·∫°ng kh√°c.")
        return None
    st.session_state.original_img = img

    if detector.startswith("DNN") and dnn_net is not None:
        boxes = detect_faces_dnn(img, dnn_net, conf_threshold=0.5)
    else:
        boxes = detect_faces_haar(img, face_cascade)

    if blur_method == "Gaussian":
        out = apply_blur_to_image(img, boxes, method="gaussian", gaussian_kernel=gaussian_kernel, draw_boxes=draw_boxes)
    else:
        out = apply_blur_to_image(img, boxes, method="pixelate", pixel_blocks=pixel_blocks, draw_boxes=draw_boxes)
    st.session_state.processed_img = out
    return out, boxes
def process_video_file(temp_input_path, temp_output_path):
    cap = cv2.VideoCapture(temp_input_path)
    if not cap.isOpened():
        st.error("Kh√¥ng m·ªü ƒë∆∞·ª£c video.")
        return None

    # L·∫•y th√¥ng tin video g·ªëc
    fps = cap.get(cv2.CAP_PROP_FPS)
    if fps <= 0 or np.isnan(fps):
        fps = 30.0
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    # Fix l·ªói s·ªë 1: ƒê·∫£m b·∫£o k√≠ch th∆∞·ªõc ƒë·ªß l·ªõn ƒë·ªÉ detect
    if width < 600:  # n·∫øu video qu√° nh·ªè (nhi·ªÅu ƒëi·ªán tho·∫°i quay 480p)
        scale = 1280 / width
        width = 1280
        height = int(height * scale)

    fourcc = cv2.VideoWriter_fourcc(*"mp4v")
    out_video = cv2.VideoWriter(temp_output_path, fourcc, fps, (width, height))

    progress_bar = st.progress(0)
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 1000  # tr√°nh chia 0
    processed_frames = 0
    detect_every_n_frames = 3  # Fix l·ªói s·ªë 2: ch·ªâ detect m·ªói 3 frame

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # Resize frame l√™n ƒë·ªÉ detect ch√≠nh x√°c h∆°n (r·∫•t quan tr·ªçng!)
        display_frame = frame.copy()
        if frame.shape[1] < 600:  # n·∫øu nh·ªè h∆°n 600px
            frame = cv2.resize(frame, (1280, int(1280 * frame.shape[0] / frame.shape[1])))

        # Ch·ªâ detect m·ªói N frame ƒë·ªÉ tƒÉng t·ªëc v√† ·ªïn ƒë·ªãnh
        if processed_frames % detect_every_n_frames == 0:
            if detector.startswith("DNN") and dnn_net is not None:
                current_boxes = detect_faces_dnn(frame, dnn_net, conf_threshold=0.5)
            else:
                # TƒÉng ƒë·ªô nh·∫°y cho Haar
                current_boxes = detect_faces_haar(frame, face_cascade, scaleFactor=1.05, minNeighbors=3)
        # C√°c frame gi·ªØa d√πng l·∫°i boxes c≈© (ng∆∞·ªùi kh√¥ng di chuy·ªÉn nhi·ªÅu)

        # √Åp d·ª•ng blur l√™n frame g·ªëc (kh√¥ng resize)
        if len(current_boxes) > 0:
            # Chuy·ªÉn boxes v·ªÅ t·ªça ƒë·ªô frame g·ªëc n·∫øu ƒë√£ resize
            scale_x = display_frame.shape[1] / frame.shape[1]
            scale_y = display_frame.shape[0] / frame.shape[0]
            scaled_boxes = []
            for (x, y, w, h) in current_boxes:
                x = int(x * scale_x)
                y = int(y * scale_y)
                w = int(w * scale_x)
                h = int(h * scale_y)
                scaled_boxes.append((x, y, w, h))
            
            if blur_method == "Gaussian":
                display_frame = apply_blur_to_image(display_frame, scaled_boxes, 
                                                  method="gaussian", gaussian_kernel=gaussian_kernel, draw_boxes=draw_boxes)
            else:
                display_frame = apply_blur_to_image(display_frame, scaled_boxes, 
                                                  method="pixelate", pixel_blocks=pixel_blocks, draw_boxes=draw_boxes)
        else:
            # N·∫øu kh√¥ng detect ƒë∆∞·ª£c ‚Üí v·∫´n ghi frame g·ªëc (kh√¥ng b·ªã ƒëen m√†n h√¨nh)
            pass

        # Resize v·ªÅ k√≠ch th∆∞·ªõc output ƒë·ªÉ file kh√¥ng qu√° n·∫∑ng
        final_frame = cv2.resize(display_frame, (width, height))
        out_video.write(final_frame)

        processed_frames += 1
        progress_bar.progress(min(1.0, processed_frames / max(frame_count, 100)))

    cap.release()
    out_video.release()
    progress_bar.empty()
    return temp_output_path

# ---------------- MAIN LOGIC ----------------

if uploaded is not None:
    fname = uploaded.name.lower()
    is_image = any(fname.endswith(ext) for ext in [".jpg", ".jpeg", ".png", ".bmp"])
    is_video = any(fname.endswith(ext) for ext in [".mp4", ".mov", ".avi", ".mkv"])
    if is_image:
        st.info("Processing image...")
        result = process_image_file(uploaded)
        if result:
            out_img, boxes = result
            st.write(f"Detected {len(boxes)} faces.")
            st.image(cv2.cvtColor(out_img, cv2.COLOR_BGR2RGB), channels="RGB", width="stretch", caption="Processed image")
            col1, col2 = st.columns(2)
            with col1:
                if st.button("Download processed image"):
                
                    _, im_buf_arr = cv2.imencode(".png", out_img)
                    st.download_button("Download PNG", im_buf_arr.tobytes(), file_name="processed.png", mime="image/png")
            with col2:
                if st.button("Unblur (restore original)"):
                    if st.session_state.original_img is not None:
                        st.image(cv2.cvtColor(st.session_state.original_img, cv2.COLOR_BGR2RGB), channels="RGB", width="stretch", caption="Original image")
                    else:
                        st.warning("Kh√¥ng c√≥ ·∫£nh g·ªëc trong phi√™n l√†m vi·ªác.")
    elif is_video:
        st.info("Received video. Processing may take a while depending on length.")
    
        t_in = tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded.name).suffix)
        t_in.write(uploaded.read())
        t_in.flush()
        t_in.close()
        st.session_state.original_video_file = t_in.name
        t_out = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
        t_out.close()
      
        processed_path = process_video_file(t_in.name, t_out.name)
        if processed_path:
            st.success("Ho√†n t·∫•t x·ª≠ l√Ω video.")
            st.session_state.processed_video_file = processed_path
           
            st.video(processed_path)
            col1, col2 = st.columns(2)
            with col1:
                if st.button("Download processed video"):
                    with open(processed_path, "rb") as f:
                        st.download_button("Download MP4", f.read(), file_name="processed.mp4", mime="video/mp4")
            with col2:
                if st.button("Unblur (play original)"):
                    if st.session_state.original_video_file:
                        st.video(st.session_state.original_video_file)
                    else:
                        st.warning("Kh√¥ng c√≥ video g·ªëc trong phi√™n l√†m vi·ªác.")
        
    else:
        st.error("ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£.")

st.markdown("---")
st.write("### Notes / Tips")
st.markdown("""
- **Haar Cascade**: nhanh, d·ªÖ d√πng, ƒë√¥i khi b·ªè s√≥t faces nghi√™ng / trong ƒëi·ªÅu ki·ªán √°nh s√°ng t·ªá.
- **DNN (res10 SSD)**: ch√≠nh x√°c h∆°n, c·∫ßn 2 file model (`deploy.prototxt` v√† `res10_300x300_ssd_iter_140000.caffemodel`). N·∫øu b·∫°n mu·ªën, t·∫£i 2 file ƒë√≥ t·ª´ ngu·ªìn OpenCV model zoo v√† nh·∫≠p ƒë∆∞·ªùng d·∫´n v√†o sidebar.
- **Video**: x·ª≠ l√Ω frame-by-frame, c√≥ th·ªÉ ch·∫≠m v·ªõi video d√†i. B·∫°n c√≥ th·ªÉ t·ªëi ∆∞u b·∫±ng c√°ch gi·∫£m ƒë·ªô ph√¢n gi·∫£i khi detect, ho·∫∑c detect m·ªói n frame r·ªìi tracking (n√¢ng cao).
- **Unblur**: ·ªü ƒë√¢y m√¨nh l∆∞u t·∫°m b·∫£n g·ªëc trong `st.session_state` ƒë·ªÉ ph·ª•c h·ªìi khi ng∆∞·ªùi d√πng nh·∫•n `Unblur`. L∆∞u √Ω session_state kh√¥ng t·ªìn t·∫°i qua nhi·ªÅu phi√™n (browser restarts).
""")

st.write("If you want, m√¨nh c√≥ th·ªÉ m·ªü r·ªông: face tracking ƒë·ªÉ blur li√™n t·ª•c tr√™n video (gi·∫£m t·∫ßn s·ªë detect), store results to folder, ho·∫∑c UI ƒë·∫πp h∆°n.")
